{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89eff3ab",
   "metadata": {},
   "source": [
    "# TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b316621f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 정규식 활용 -> 특수문자 제거\n",
    "import re\n",
    "\n",
    "# 한글 형태소 분석기\n",
    "from konlpy.tag import Okt\n",
    "okt = Okt()\n",
    "\n",
    "# 단어 빈도수 세기\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b51fddc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_str = '20250818'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "49a2c0db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(349, 4)\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "word",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "count",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "51d9d45f-5e6a-4387-b7c4-0f27755c2a28",
       "rows": [
        [
         "0",
         "속보",
         "13"
        ],
        [
         "1",
         "관세",
         "10"
        ],
        [
         "2",
         "김건희",
         "10"
        ],
        [
         "3",
         "특검",
         "10"
        ],
        [
         "4",
         "AI",
         "9"
        ],
        [
         "5",
         "한국",
         "8"
        ],
        [
         "6",
         "영상",
         "7"
        ],
        [
         "7",
         "규제",
         "6"
        ],
        [
         "8",
         "대통령",
         "6"
        ],
        [
         "9",
         "상반기",
         "6"
        ],
        [
         "10",
         "미국",
         "6"
        ],
        [
         "11",
         "매출",
         "6"
        ],
        [
         "12",
         "삼성",
         "6"
        ],
        [
         "13",
         "선정",
         "5"
        ],
        [
         "14",
         "청년",
         "5"
        ],
        [
         "15",
         "크라",
         "5"
        ],
        [
         "16",
         "바이오",
         "5"
        ],
        [
         "17",
         "조국",
         "5"
        ],
        [
         "18",
         "국내",
         "4"
        ],
        [
         "19",
         "모델",
         "4"
        ],
        [
         "20",
         "PRO",
         "4"
        ],
        [
         "21",
         "건진",
         "4"
        ],
        [
         "22",
         "마켓",
         "4"
        ],
        [
         "23",
         "대응",
         "4"
        ],
        [
         "24",
         "하락",
         "4"
        ],
        [
         "25",
         "세계",
         "4"
        ],
        [
         "26",
         "중국",
         "4"
        ],
        [
         "27",
         "종목",
         "4"
        ],
        [
         "28",
         "반도체",
         "4"
        ],
        [
         "29",
         "여행",
         "4"
        ],
        [
         "30",
         "우려",
         "4"
        ],
        [
         "31",
         "소환",
         "4"
        ],
        [
         "32",
         "공식",
         "4"
        ],
        [
         "33",
         "거래",
         "4"
        ],
        [
         "34",
         "출시",
         "4"
        ],
        [
         "35",
         "역대",
         "4"
        ],
        [
         "36",
         "서비스",
         "4"
        ],
        [
         "37",
         "철강",
         "4"
        ],
        [
         "38",
         "사주",
         "3"
        ],
        [
         "39",
         "넥스트",
         "3"
        ],
        [
         "40",
         "증권",
         "3"
        ],
        [
         "41",
         "치료",
         "3"
        ],
        [
         "42",
         "판매",
         "3"
        ],
        [
         "43",
         "확정",
         "3"
        ],
        [
         "44",
         "했는데",
         "3"
        ],
        [
         "45",
         "한화",
         "3"
        ],
        [
         "46",
         "HK",
         "3"
        ],
        [
         "47",
         "안전",
         "3"
        ],
        [
         "48",
         "중지",
         "3"
        ],
        [
         "49",
         "질환",
         "3"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 1174
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>속보</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>관세</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>김건희</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>특검</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AI</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1169</th>\n",
       "      <td>긴장</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1170</th>\n",
       "      <td>시킬</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1171</th>\n",
       "      <td>의도</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1172</th>\n",
       "      <td>유승준</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1173</th>\n",
       "      <td>최종</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1174 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     word  count\n",
       "0      속보     13\n",
       "1      관세     10\n",
       "2     김건희     10\n",
       "3      특검     10\n",
       "4      AI      9\n",
       "...   ...    ...\n",
       "1169   긴장      1\n",
       "1170   시킬      1\n",
       "1171   의도      1\n",
       "1172  유승준      1\n",
       "1173   최종      1\n",
       "\n",
       "[1174 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 파일 불러오기\n",
    "raw_data_gen = pd.read_csv(f\"/Users/leesangwon/Documents/ThemeStock_file/hankyung_general_{date_str}.csv\")\n",
    "raw_data_i = pd.read_csv(f\"/Users/leesangwon/Documents/ThemeStock_file/hankyung_i_{date_str}.csv\")\n",
    "raw_data_g = pd.read_csv(f\"/Users/leesangwon/Documents/ThemeStock_file/hankyung_g_{date_str}.csv\")\n",
    "\n",
    "# 하나의 파일로 유니온\n",
    "raw_data = pd.concat([raw_data_gen, raw_data_i, raw_data_g], ignore_index=True)\n",
    "print(raw_data.shape)\n",
    "\n",
    "# 완전일치 중복기사 제거\n",
    "df = raw_data.drop_duplicates(subset=['title', 'text'], keep='first').copy()\n",
    "\n",
    "# title에 [속보] 또는 [포토] 포함 시 text를 NaN으로 변경\n",
    "df.loc[df['title'].str.contains(r'\\[속보\\]|\\[포토\\]', regex=True), 'text'] = np.nan\n",
    "\n",
    "# null셀을 빈칸으로 만들기\n",
    "df['title'] = df['title'].fillna('')\n",
    "df['text'] = df['text'].fillna('')\n",
    "\n",
    "# 특수문자 등 전처리\n",
    "df['text_clean'] = df['text'].apply(lambda t: re.sub(r'[^가-힣A-Za-z&\\$₩]', ' ', t))\n",
    "df['title_clean'] = df['title'].apply(lambda t: re.sub(r'[^가-힣A-Za-z&\\$₩]', ' ', t))\n",
    "df.head(3)\n",
    "\n",
    "\n",
    "###########################\n",
    "\n",
    "\n",
    "# 불용어 불러오기 (줄바꿈 기준 분리)\n",
    "with open(\"/Users/leesangwon/Documents/ThemeStock_file/stopwords_kor.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    stopwords = f.read()\n",
    "\n",
    "# 불용어 제거 함수\n",
    "def remove_stopwords(text_clean):\n",
    "    if not isinstance(text_clean, str):\n",
    "        return ''\n",
    "    return ' '.join([word for word in text_clean.split() if word not in stopwords])\n",
    "\n",
    "# 조사 제거 함수\n",
    "def remove_josa(text):\n",
    "    if not isinstance(text, str):\n",
    "        return ''\n",
    "    return ' '.join([word for word, pos in okt.pos(text) if pos != 'Josa'])\n",
    "\n",
    "# 조사 제거 → 불용어 제거 순차 적용\n",
    "df['title_clean'] = df['title_clean'].apply(remove_josa)  # 조사 제거\n",
    "df['title_clean'] = df['title_clean'].apply(remove_stopwords)  # 불용어 제거\n",
    "\n",
    "df['text_clean'] = df['text_clean'].apply(remove_josa)  # 조사 제거\n",
    "df['text_clean'] = df['text_clean'].apply(remove_stopwords)  # 불용어 제거\n",
    "\n",
    "\n",
    "\n",
    "# 1. 전체 단어 모으기\n",
    "all_words = []\n",
    "for text in df['title_clean']:\n",
    "    if isinstance(text, str):\n",
    "        all_words.extend(text.split())  # 공백 기준 토큰 분리\n",
    "\n",
    "# 2. 빈도 계산\n",
    "word_counts = Counter(all_words)\n",
    "\n",
    "# 3. DataFrame 변환\n",
    "freq_df = pd.DataFrame(word_counts.items(), columns=['word', 'count'])\n",
    "freq_df = freq_df.sort_values(by='count', ascending=False).reset_index(drop=True)\n",
    "\n",
    "freq_df # 상위 20개 단어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9c618038",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_df.to_csv(f\"/Users/leesangwon/Documents/ThemeStock_file/title_TF_{date_str}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6ff206",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
