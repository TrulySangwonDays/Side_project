{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: konlpy in /opt/anaconda3/lib/python3.12/site-packages (0.6.0)\n",
      "Requirement already satisfied: JPype1>=0.7.0 in /opt/anaconda3/lib/python3.12/site-packages (from konlpy) (1.5.0)\n",
      "Requirement already satisfied: lxml>=4.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from konlpy) (5.2.1)\n",
      "Requirement already satisfied: numpy>=1.6 in /opt/anaconda3/lib/python3.12/site-packages (from konlpy) (1.26.4)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.12/site-packages (from JPype1>=0.7.0->konlpy) (23.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install konlpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 네이버 뉴스기사 크롤링 (지난 일주일 간)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 크롤링 완료: /Users/leesangwon/Downloads/트럼프_2025-02-24_to_2025-03-02_news_data.csv 저장됨.\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "import urllib.parse\n",
    "import time\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "#####################################################\n",
    "# 검색어 및 날짜 설정\n",
    "text = \"트럼프\"  # 검색어 입력\n",
    "base_date = \"2025-03-03\"  # 기준 날짜\n",
    "#####################################################\n",
    "\n",
    "# 날짜 변환\n",
    "base_date_dt = datetime.strptime(base_date, \"%Y-%m-%d\")\n",
    "\n",
    "# 하루씩 빼면서 일주일치 날짜 리스트 생성\n",
    "day_list = [(base_date_dt - timedelta(days=i)).strftime(\"%Y-%m-%d\") for i in range(1, 8)]\n",
    "\n",
    "# ChromeDriver 경로 설정\n",
    "driver_path = \"/Users/leesangwon/Desktop/chromedriver-mac-arm64/chromedriver\"  # 크롬드라이버 경로 입력\n",
    "service = Service(driver_path)\n",
    "\n",
    "# 웹드라이버 초기화\n",
    "driver = webdriver.Chrome(service=service)\n",
    "\n",
    "# 전체 데이터 저장 리스트\n",
    "all_data = []\n",
    "\n",
    "for date in day_list:\n",
    "    y, m, d = date.split(\"-\")  # 연, 월, 일 분리\n",
    "\n",
    "    # URL 생성\n",
    "    encoded_text = urllib.parse.quote(text)  # 검색어 URL 인코딩\n",
    "    url = f\"https://search.naver.com/search.naver?where=news&query={encoded_text}&sm=tab_opt&sort=0&photo=0&field=0&pd=3&ds={y}.{m}.{d}&de={y}.{m}.{d}&nso=so%3Ar%2Cp%3Afrom{y}{m}{d}to{y}{m}{d}\"\n",
    "\n",
    "    # 페이지 열기\n",
    "    driver.get(url)\n",
    "    time.sleep(1.5)  # 페이지 로딩 대기\n",
    "\n",
    "    # 기사 개수를 체크하면서 스크롤 조절\n",
    "    scroll_count = 0\n",
    "    while scroll_count < 5:  # 최대 5회까지만 스크롤\n",
    "        titles = driver.find_elements(By.CSS_SELECTOR, \".news_tit\")\n",
    "        if len(titles) >= 30:  # 30개 이상이면 스크롤 중단\n",
    "            break\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(1.2)\n",
    "        scroll_count += 1\n",
    "\n",
    "    # 기사 제목, 날짜, 언론사, 내용 크롤링\n",
    "    titles = driver.find_elements(By.CSS_SELECTOR, \".news_tit\")\n",
    "    dates = driver.find_elements(By.CSS_SELECTOR, \".info_group > span\")\n",
    "    scripts = driver.find_elements(By.CSS_SELECTOR, \".dsc_txt_wrap\")\n",
    "    press = driver.find_elements(By.CSS_SELECTOR, \".info_group > a.press\")\n",
    "\n",
    "    # 하루 단위로 데이터 저장\n",
    "    day_data = []\n",
    "    for title, date, script, p in zip(titles[:30], dates[:30], scripts[:30], press[:30]):\n",
    "        day_data.append({\n",
    "            \"Title\": title.text,\n",
    "            \"Date\": date.text,\n",
    "            \"Press\": p.text,\n",
    "            \"Description\": script.text\n",
    "        })\n",
    "\n",
    "    all_data.extend(day_data)  # 전체 데이터에 추가\n",
    "\n",
    "# 데이터프레임 생성 및 CSV 저장\n",
    "df = pd.DataFrame(all_data)\n",
    "csv_filename = f\"/Users/leesangwon/Downloads/{text}_{day_list[-1]}_to_{day_list[0]}_news_data.csv\"\n",
    "df.to_csv(csv_filename, index=False)\n",
    "\n",
    "# 드라이버 종료\n",
    "driver.quit()\n",
    "\n",
    "print(f\"✅ 크롤링 완료: {csv_filename} 저장됨.\")\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 형태소 분석 및 토크나이징"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ CSV 파일 저장 완료: /Users/leesangwon/Downloads/freq_딥시크_2025-02-23_to_2025-03-01_news_data.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/leesangwon/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "from nltk.probability import FreqDist\n",
    "from konlpy.tag import Kkma\n",
    "\n",
    "# 파일명 지정\n",
    "news_data = \"딥시크_2025-02-23_to_2025-03-01_news_data\"\n",
    "csv_filename = f\"/Users/leesangwon/Downloads/{news_data}.csv\"  # CSV 파일 경로\n",
    "\n",
    "# CSV 파일 로드\n",
    "df = pd.read_csv(csv_filename, encoding=\"utf-8-sig\")  \n",
    "\n",
    "# \"Title\"과 \"description\"을 합쳐서 하나의 문자열로 변환\n",
    "df = df.dropna(subset=[\"Title\", \"Description\"])  # NaN 제거\n",
    "text = \" \".join(df[\"Title\"].astype(str) + \" \" + df[\"Description\"].astype(str))\n",
    "\n",
    "# Kkma 형태소 분석기 초기화\n",
    "kkma = Kkma()\n",
    "\n",
    "# 형태소 분석 후 명사(NNG, NNP) 추출\n",
    "morphs = kkma.pos(text)\n",
    "nouns = [word for word, tag in morphs if tag in [\"NNG\", \"NNP\"]]\n",
    "\n",
    "# NLTK를 이용하여 단어 빈도수 분석\n",
    "nltk.download(\"punkt\")  # 첫 실행 시 필요\n",
    "freq_dist = FreqDist(nouns)\n",
    "\n",
    "# 데이터프레임 생성\n",
    "df_freq = pd.DataFrame(freq_dist.items(), columns=[\"단어\", \"빈도수\"])\n",
    "\n",
    "# CSV 파일 저장\n",
    "output_csv_filename = f\"/Users/leesangwon/Downloads/freq_{news_data}.csv\"\n",
    "df_freq.to_csv(output_csv_filename, index=False, encoding=\"utf-8-sig\")  # utf-8-sig로 한글 깨짐 방지\n",
    "\n",
    "print(f\"✅ CSV 파일 저장 완료: {output_csv_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
